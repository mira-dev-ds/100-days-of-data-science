# ğŸ“ˆ Linear Regression Concepts (Day 3)

Welcome to **Day 3** of my 100 Days of Data Science journey!  
Todayâ€™s focus was on understanding the **core ideas behind Linear Regression**, one of the simplest and most powerful algorithms in Machine Learning.

---

## ğŸ§  What I Learned

- **What Linear Regression is:**  
  A supervised learning algorithm that helps us predict a continuous outcome (like price, marks, or temperature) based on input data.

- **Hypothesis Function:**  
  The equation that defines our modelâ€™s prediction:  
  \[
  y = mX + c
  \]  
  where `m` = slope, and `c` = intercept.

- **Cost Function:**  
  A mathematical way to measure how far our predictions are from actual results.  
  Linear regression uses **Mean Squared Error (MSE)** to calculate this.

- **Gradient Descent:**  
  An optimization technique that helps find the best values of `m` and `c` by minimizing the cost function â€” step by step.

---

## ğŸ§© Key Takeaways

- Machine Learning models *learn by minimizing error.*
- Linear Regression builds intuition about how models â€œfitâ€ data.
- Understanding math behind the model is more important than jumping straight into code.

---

## ğŸ”— References
- [GeeksforGeeks: Linear Regression Introduction](https://www.geeksforgeeks.org/linear-regression-introduction/)  
- Krish Naikâ€™s YouTube Playlist on Machine Learning  

---

## ğŸ’» Next Step
Tomorrow, Iâ€™ll **implement Linear Regression using Python (Scikit-learn)**  
and visualize how the model fits the data.

---

ğŸ“‚ GitHub Repository: [100 Days of Data Science](https://github.com/Data-withMirunalini/100-days-of-data-science/tree/main)  
ğŸ“ Day 3 Folder: [Linear Regression Concepts](https://github.com/Data-withMirunalini/100-days-of-data-science/blob/main/Day03_LinearRegression/Day3_Linear_Regression.ipynb)

---

#100DaysOfDataScience #MachineLearning #LinearRegression #DataScienceJourney
