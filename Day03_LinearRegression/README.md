# 📈 Linear Regression Concepts (Day 3)

Welcome to **Day 3** of my 100 Days of Data Science journey!  
Today’s focus was on understanding the **core ideas behind Linear Regression**, one of the simplest and most powerful algorithms in Machine Learning.

---

## 🧠 What I Learned

- **What Linear Regression is:**  
  A supervised learning algorithm that helps us predict a continuous outcome (like price, marks, or temperature) based on input data.

- **Hypothesis Function:**  
  The equation that defines our model’s prediction:  
  \[
  y = mX + c
  \]  
  where `m` = slope, and `c` = intercept.

- **Cost Function:**  
  A mathematical way to measure how far our predictions are from actual results.  
  Linear regression uses **Mean Squared Error (MSE)** to calculate this.

- **Gradient Descent:**  
  An optimization technique that helps find the best values of `m` and `c` by minimizing the cost function — step by step.

---

## 🧩 Key Takeaways

- Machine Learning models *learn by minimizing error.*
- Linear Regression builds intuition about how models “fit” data.
- Understanding math behind the model is more important than jumping straight into code.

---

## 🔗 References
- [GeeksforGeeks: Linear Regression Introduction](https://www.geeksforgeeks.org/linear-regression-introduction/)  
- Krish Naik’s YouTube Playlist on Machine Learning  

---

## 💻 Next Step
Tomorrow, I’ll **implement Linear Regression using Python (Scikit-learn)**  
and visualize how the model fits the data.

---

📂 GitHub Repository: [100 Days of Data Science](https://github.com/Data-withMirunalini/100-days-of-data-science/tree/main)  
📁 Day 3 Folder: [Linear Regression Concepts](https://github.com/Data-withMirunalini/100-days-of-data-science/blob/main/Day03_LinearRegression/Day3_Linear_Regression.ipynb)

---

#100DaysOfDataScience #MachineLearning #LinearRegression #DataScienceJourney
